{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, re\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tekal import *\n",
    "from uitintegratie import *\n",
    "import pandas as pd\n",
    "import dill\n",
    "\n",
    "import numpy.ma as ma\n",
    "import fit_beta as fb\n",
    "from gumplot import *\n",
    "import scipy.special as scs\n",
    "import bisect\n",
    "from IPython.lib.deepreload import reload as dreload\n",
    "import inspect\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stappen om tot de werklijn te komen mét gecombineerde onzekerheid</h2>\n",
    "<ul>\n",
    "    <li> Er is uitgegaan van de afvoer jaarmaxima berekend door HBV op basis van de <a href=\"#ref2021\">referentie simulatie</a> met de neerslaggenerator, uitgedrukt als $\\mu_{HBV}$</li>\n",
    "    <li> De HBV afvoermaxima $\\mu_{HBV}$ worden getransformeerd naar Sobek afvoermaxima $\\mu_{SBK}$ middels de     regressie         (H.vd Boogaard)</li>\n",
    "<li> <b>Onzekerheid Meteo + HBV:</b></li>    \n",
    "    <ul>\n",
    "        <li> De onzekerheid van deze maxima wordt voorgesteld als een verstoring op $\\mu_{HBV}$ met een verdeling $N(0,\\sigma_{HBV})$</li>\n",
    "        <li> Deze onzekerheid is vastgesteld met behulp van een Jackknife analyse (gevoeligheid neerslagdata) en een GLUE analyse (HBV modelonzekerheid)</li>\n",
    "    </ul>\n",
    "    <li> <b>Onzekerheid hydraulica:</b></li>    \n",
    "    <ul>\n",
    "        <li> Modelstudies zijn uitgevoerd met SOBEK onder variërende hydraulische condities (parameter variaties) voor specifieke cases.</li>\n",
    "        <li> Per case vormen de vekregen SOBEK resultaten voor verwschillende parametersets een populatie.</li>\n",
    "        <li> Aan elke populatie zijn de parameters $\\alpha, \\beta, A, B$ van de 4-parameter Beta verdeling gefit</li>\n",
    "        <li> Uit de parametersets </li>\n",
    "        <li> Centreer een beta verdeling om nul, gebaseerd met parameters die een functie zijn van $\\mu_{sobek}$</li>\n",
    "        <li> Sample de gecombineerde verdeling:\n",
    "            <ul>\n",
    "                <li> Trek uit de normale verdeling voor de \"meteo/jackknife onzekerheid\" (!nb: een HBV resultaat)</li>\n",
    "                <li> Trek uit de bijbehorende beta verdeling</li>\n",
    "                <li> sommeer</li>\n",
    "            </ul>\n",
    "        <li> Fit nieuwe beta parameters </li>\n",
    "        <li> Bepaal betrouwbaarheids intervallen </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevante herhaaltijden\n",
    "Tretlist = [2,5,10,30,100,300,1250,3000,10000,30000,100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voor gumbelplotjes\n",
    "def add_return_period(tretlist,ax,ymax,yrange):\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(ax.get_xlim())\n",
    "    lbl = [\"%d\"%int(tr) for tr in tretlist]\n",
    "    pos = [-np.log(-np.log(1.-1./tr)) for tr in tretlist]\n",
    "    for tr in tretlist:\n",
    "        xpos = -np.log(-np.log(1.-1./tr))\n",
    "        ax2.plot([xpos,xpos],[0,ymax],color='green',linestyle='--', alpha=0.6)\n",
    "    ax2.set_xticks(pos)\n",
    "    ax2.set_yticks(np.arange(0,ymax,yrange))\n",
    "    ax2.yaxis.set_minor_locator(MultipleLocator(1000))\n",
    "    ax2.set_xticklabels(lbl, rotation='vertical')\n",
    "    return ax2\n",
    "\n",
    "def add_gum_axis(tretlist,ax,ymax,yrange):\n",
    "    ax2 = add_return_period(tretlist,ax,ymax,yrange)\n",
    "    grid2 = ax2.grid()\n",
    "    grid1 = ax.grid(which='major')\n",
    "    grid1 = ax.grid(which='minor', color='grey', linewidth=0.1)\n",
    "    ylbl1 = ax.set_ylabel('Discharge [m3 s-1]')\n",
    "    xlbl1 = ax.set_xlabel('Standardised Gumbel Variate [-]')\n",
    "    xlbl2 = ax2.set_xlabel('Return period [year]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regressie HBV-to-SOBEK Rijn</h3>\n",
    "Uit regressie is een relatie bepaald uit de HBV-(piek)afvoeren $Q_h$ en de bijbehorende Sobek (piek)afvoeren $Q_s$ als volgt (Henk vd Boogaard, <tt>regression_2018</tt>):\n",
    "    $$Q_s\\,=\\,C\\,+\\,r_1Q_h\\,+\\,(r_2-r_1)\\sigma_1\\log\\left(1+\\exp\\left(\\frac{Q_h-\\mu_1}{\\sigma_1}\\right)\\right)$$\n",
    "    $$\\phantom{Q_s\\,=\\,C\\,+\\,r_1Q_h\\,}+\\,(r_3-r_2)\\,\\sigma_2\\log\\left(1+\\exp\\left(\\frac{Q_h-\\mu_2}{\\sigma_2}\\right)\\right)$$    \n",
    "    $$\\phantom{Q_s\\,=\\,C\\,+\\,r_1Q_h\\,}+\\,(r_4-r_3)\\,\\sigma_3\\log\\left(1+\\exp\\left(\\frac{Q_h-\\mu_3}{\\sigma_3}\\right)\\right)$$\n",
    "    $$\\phantom{Q_s\\,=\\,C\\,+\\,r_1Q_h\\,}+\\,(r_5-r_4)\\,\\sigma_4\\log\\left(1+\\exp\\left(\\frac{Q_h-\\mu_4}{\\sigma_4}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math   # Crucial import !!!\n",
    "def regression_2018(x, fit_regr=False):\n",
    "    c      = 342.254390\n",
    "    r1     = 0.91577902\n",
    "    mu1    = 14442.2780 #ORIG\n",
    "    sigma1 = 307.118620\n",
    "    r2     = 0.32752076\n",
    "    mu2    = 18573.2200 #ORIG\n",
    "    sigma2 = 2.71804449E-14\n",
    "    r3     = 0.53632634 #ORIG\n",
    "    mu3    = 21904.1250 #ORIG\n",
    "    sigma3 = 136.807970  \n",
    "    r4     = 0.21296795\n",
    "    mu4    = 26177.6500 #ORIG\n",
    "    sigma4 = 79.5476640\n",
    "    r5     = 0.00000000\n",
    "    if fit_regr == True:\n",
    "        mu1    = 14800.0000\n",
    "        mu2    = 17750.0000\n",
    "        r3     = 0.75000000\n",
    "        mu3    = 20000.0000\n",
    "    \n",
    "    x_ = []\n",
    "    for value in x:\n",
    "        z1 = (value-mu1)/sigma1\n",
    "        z2 = (value-mu2)/sigma2\n",
    "        z3 = (value-mu3)/sigma3\n",
    "        z4 = (value-mu4)/sigma4\n",
    "        \n",
    "        a1 = (r1*value)\n",
    "        a2 = ((r2-r1)*sigma1*np.log(1+np.exp(z1)))\n",
    "        try:\n",
    "            a3 = ((r3-r2)*sigma2*np.log(1+math.exp(z2)))\n",
    "        except:\n",
    "            a3 = ((r3-r2)*sigma2*z2)\n",
    "        a4 = ((r4-r3)*sigma3*np.log(1+np.exp(z3)))\n",
    "        a5 = ((r5-r4)*sigma4*np.log(1+np.exp(z4)))\n",
    "        \n",
    "        y = c + a1 + a2 + a3 + a4 + a5\n",
    "        x_.append(y)\n",
    "\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees oude werklijn\n",
    "column_Tret  = 8\n",
    "column_Qref  = 9\n",
    "column_Sigma = 10\n",
    "\n",
    "with open('./oude_getallen.csv',\"r\") as fnin:\n",
    "    sgv_list = []\n",
    "    mu_list = []\n",
    "    sigma_list = []\n",
    "    while True:\n",
    "        line = fnin.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if line[0] in '#*':\n",
    "            continue\n",
    "        columns = line.strip().split(';')\n",
    "        Tret = float(columns[column_Tret-1])\n",
    "        mu_value = float(columns[column_Qref-1])\n",
    "        sigma_value = float(columns[column_Sigma-1])\n",
    "        sgv_list.append(-np.log(-np.log(1.-1./Tret)))\n",
    "        mu_list.append(mu_value)\n",
    "        sigma_list.append(sigma_value)\n",
    "nx_old = len(sgv_list)        \n",
    "np_sgv_old = np.array(sgv_list)        \n",
    "np_qref_old = np.array(mu_list)\n",
    "np_sigma_old = np.array(sigma_list)\n",
    "rijn_old={'sgv':np.array(sgv_list),'mu':np.array(mu_list),'sigma':np.array(sigma_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Referentie werklijn voor de Rijn (2021)</H3>\n",
    "<a id=\"ref2021\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees de referentie werklijn voor de Rijn (2021)\n",
    "with open('optimal_slice_mem6d_Fwet_500K_1951-2015_window61_part001-025_MAX.csv',\"r\") as fnin:\n",
    "    qref = []\n",
    "    minimum = 1000000.\n",
    "    while True:\n",
    "        line = fnin.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        syear, sqvalue = line.strip().split(',')\n",
    "        try:\n",
    "            year = int(syear)\n",
    "            qvalue = float(sqvalue)\n",
    "        except:\n",
    "            continue\n",
    "        bisect.insort(qref,qvalue)\n",
    "nx = len(qref)\n",
    "np_qref = np.array(qref)\n",
    "np_sgv = -np.log(-np.log((np.array(list(range(nx)))+1.-0.3)/(nx+0.4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees TEKAL file met Meteo onzekerheden\n",
    "listTEKALBlocks(\"Final_FreqCurve_Rhine_HBV.tek\")\n",
    "# Lees TEKAL file (Henk vd Boogaard, met HBV onzekerheden)\n",
    "UncMeteo = readTEKAL('Final_FreqCurve_Rhine_HBV.tek','BL01',skip=99)\n",
    "tbl_mu_Meteo = UncMeteo[3]\n",
    "tbl_sigma_Meteo = UncMeteo[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabel interpolatie\n",
    "def interpolate(xx,yy,x,default=np.nan,fraction=-1):\n",
    "    if x<xx[0] or x>xx[-1]:\n",
    "        return default\n",
    "    for i in range(len(xx)-1):\n",
    "        if (x>=xx[i] and x<=xx[i+1]):\n",
    "            if fraction<0.0:\n",
    "                w=(x-xx[i])/(xx[i+1]-xx[i])   # use fraction=0.0 for yy[i] and fraction=1.0 for yy[i+1]\n",
    "            else:\n",
    "                w=fraction\n",
    "            return (1.-w)*yy[i] + w*yy[i+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voeg de geinterpoleerde sigma's toe als onzekerheid\n",
    "sigma_Meteo = []\n",
    "for i in tqdm(list(range(np_qref.size))):\n",
    "    sigma_Meteo.append(interpolate(tbl_mu_Meteo,tbl_sigma_Meteo,np_qref[i],default=10))\n",
    "np_sigma_Meteo = np.array(sigma_Meteo)\n",
    "\n",
    "rijn_new={'sgv':np_sgv,'mu':np_qref,'sigma':np_sigma_Meteo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees de observaties(blokmaxima, toestand 2004) - NOT USED\n",
    "with open(\"observations\\\\Lobith_HR2006_AM.csv\",\"r\") as fnin:\n",
    "    qhis = []\n",
    "    while True:\n",
    "        line = fnin.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        try:\n",
    "            ss = line.split(';')\n",
    "            year = int(ss[0])\n",
    "            qmax_1977 = float(ss[1])\n",
    "            qmax_2004 = float(ss[2])\n",
    "            bisect.insort(qhis,qmax_2004)\n",
    "        except:\n",
    "            pass\n",
    "nxhis = len(qhis)\n",
    "rijn_obs = {}\n",
    "rijn_obs['sgv'] = -np.log(-np.log((np.array(list(range(nxhis)))+1.-0.3)/(nxhis+0.4)))\n",
    "rijn_obs['mu'] = np.array(qhis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees de observaties(blokmaxima, toestand 2004)\n",
    "with open(\"observations\\\\Historical TQ_1901_2000_K.csv\",\"r\") as fnin:\n",
    "    qhis = []\n",
    "    years = []\n",
    "    months = []\n",
    "    while True:\n",
    "        line = fnin.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        try:\n",
    "            ss = line.split(',')\n",
    "            year = int(ss[0][0:4])\n",
    "            month= int(ss[0][4:6])\n",
    "            q = float(ss[8])\n",
    "            years.append(year)\n",
    "            months.append(month)\n",
    "            qhis.append(q)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "df = pd.DataFrame([years,months,qhis]).T\n",
    "df.columns = ['Y','M','Q']\n",
    "df['HY'] = df['Y']\n",
    "df['HY'][df['M'] > 9] =  df['HY']+1\n",
    "df_max = np.sort(df.groupby(df['HY']).max()['Q'])\n",
    "\n",
    "nxhis = len(df_max)\n",
    "rijn_obs = {}\n",
    "rijn_obs['sgv'] = -np.log(-np.log((np.array(list(range(nxhis)))+1.-0.3)/(nxhis+0.4)))\n",
    "rijn_obs['mu'] = np.array(df_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot oud versus observations\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 2000\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "ax.plot(rijn_old['sgv'],rijn_old['mu'],'r-',label=\"WBI2017\")\n",
    "ax.plot(rijn_new['sgv'],regression_2018(rijn_new['mu']),'b-',label=\"GRADE'21\")\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_01.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hulp routines voor de uitintegratie\n",
    "def normal_cdf(x,parms):\n",
    "    mu = parms[0]\n",
    "    sigma = parms[1]\n",
    "    return (1.0 + erf((x-mu) / sigma / sqrt(2.0))) / 2.0\n",
    "\n",
    "def normal_pdf(x,parms):\n",
    "    mu = parms[0]\n",
    "    sigma = parms[1]\n",
    "    return exp(-0.5*((x-mu)/2./sigma)**2)/(sigma*(2*pi)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voer een uitintegratie uit voor de oude resultaten\n",
    "nx_old = len(rijn_old['sgv'])\n",
    "rijn_old['uitintegratie']={}\n",
    "rijn_parms = {'distpar':[(rijn_old['mu'][i] ,rijn_old['sigma'][i]) for i in range(nx_old)],\n",
    "              'F':np.exp(-np.exp(-rijn_old['sgv']))}\n",
    "rijn_old['uitintegratie']['levels'] = np.array(list(range(5000,20000,100)))\n",
    "rijn_cdf = outintegrate(rijn_parms, rijn_old['uitintegratie']['levels'], normal_cdf)\n",
    "rijn_old['uitintegratie']['sgv'] = -np.log(-np.log(rijn_cdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot oud versus observations met \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 2000\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "ax.plot(rijn_old['sgv'],rijn_old['mu'],'r-',label=\"WBI2017\")\n",
    "ax.plot(rijn_old['sgv'],rijn_old['mu']+1.96*rijn_old['sigma'],'r--')\n",
    "ax.plot(rijn_old['sgv'],rijn_old['mu']-1.96*rijn_old['sigma'],'r--')\n",
    "ax.plot(rijn_old['uitintegratie']['sgv'],rijn_old['uitintegratie']['levels'],'k-',label=\"WBI2017 - processed uncertainties\")\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_02.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ensembles into dictionaries\n",
    "# Read the file into a dictionary, labelled by event->timeseries\n",
    "datafile = 'read_Qmax_sums_results.csv'\n",
    "sep = ';'\n",
    "with open(datafile,\"r\") as fnin:\n",
    "    line = fnin.readline().strip()\n",
    "    colnames = re.sub(r'[^\\x00-\\x7F]','', line).split(sep)\n",
    "    ensembles = { colname:[] for colname in colnames}\n",
    "    while line:\n",
    "        line = fnin.readline()\n",
    "        linesplit = line.strip().split(sep)\n",
    "        for i in range(len(linesplit)):\n",
    "            if linesplit[i]:\n",
    "                try:\n",
    "                    ensembles[colnames[i]].append(float(linesplit[i].replace(',','.')))\n",
    "                except:\n",
    "                    ensembles[colnames[i]].append(linesplit[i])\n",
    "\n",
    "# Select realizations from ensembles:\n",
    "first_realization = 0\n",
    "last_realization = 100\n",
    "refnr = 113\n",
    "\n",
    "label2nr = {}\n",
    "rownames = ensembles['Scenario']\n",
    "for i in range(len(rownames)):\n",
    "    label2nr[rownames[i]] = i\n",
    "selected = ['Sum%d'%dd for dd in range (first_realization,last_realization+1)]    # selected labels for realizations\n",
    "selnr = [label2nr[rowname] for rowname in selected]\n",
    "\n",
    "# Determine min, max, alpha, beta for each ensemble\n",
    "irow_ref = label2nr['Sum%d'%refnr]\n",
    "a = np.array([])\n",
    "b = np.array([])\n",
    "alpha = np.array([])\n",
    "beta = np.array([])\n",
    "qref = np.array([])\n",
    "\n",
    "a_2se = np.array([])\n",
    "b_2se = np.array([])\n",
    "alpha_2se = np.array([])\n",
    "beta_2se = np.array([])\n",
    "colnames.pop(0)\n",
    "for icol in range(1,len(colnames)): \n",
    "    sample=np.array([ensembles[colnames[icol]][i] for i in selnr])\n",
    "    est,var = fb.fitBetaMomentsJack(sample)\n",
    "    \n",
    "    alpha = np.append(alpha,est[0])\n",
    "    beta = np.append(beta,est[1])\n",
    "    a = np.append(a,est[2])\n",
    "    b = np.append(b,est[3])\n",
    "    alpha_2se = np.append(alpha,var[2])\n",
    "    beta_2se = np.append(beta,var[3])\n",
    "    a_2se = np.append(a,var[0])\n",
    "    b_2se = np.append(b,var[1])\n",
    "    qref = np.append(qref,ensembles[colnames[icol]][irow_ref])\n",
    "    \n",
    "sys.stdout.write(\"%11s    %8s %8s       %8s    %8s    %s\\n\"%('Ref','alpha','beta','A', 'B', 'Label'))\n",
    "for i in range(len(qref)):\n",
    "    sys.stdout.write(\"%8.5f    %8.5f %8.5f    %8.5f %8.5f    %s\\n\"%(qref[i],alpha[i],beta[i],a[i],b[i],colnames[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Lezen van Deltares TEKAL blokken en tabel-interpolatie\n",
    "def getTEKALLine(fn):\n",
    "    while True:\n",
    "        line = fn.readline()\n",
    "        if not(line):\n",
    "             return(line)\n",
    "        if (line[0]!=\"*\"):\n",
    "             return(line)\n",
    "\n",
    "def readTEKAL(fnin,blklbl,**kwargs):\n",
    "# Read selected TEKAL block in a list of numpy 1d-arrays\n",
    "    try:\n",
    "        each = int(kwargs['skip'])+1\n",
    "    except:\n",
    "        each = 1\n",
    "    with open(fnin,\"r\") as fn:\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            line = getTEKALLine(fn)\n",
    "            if not(line):\n",
    "                raise (Exception(\"Label \"+blklbl+\" not found!\"))\n",
    "            if line.strip()==blklbl:\n",
    "                line = getTEKALLine(fn)\n",
    "                try:\n",
    "                    nrowcol = line.split()\n",
    "                    nrow, ncol = int(nrowcol[0]), int(nrowcol[1])\n",
    "                    break\n",
    "                except:\n",
    "                    raise (Exception(\"Block \"+blklbl+\" corrupt!\"))\n",
    "        data =[]   # list of numpy arrays\n",
    "        for icol in range(ncol):\n",
    "            data.append(np.array([]))\n",
    "        for irow in range(nrow):\n",
    "            line = getTEKALLine(fn)\n",
    "            if not(line):\n",
    "                break\n",
    "            strings = line.split()\n",
    "            if cnt%each == 0:\n",
    "                for icol in range(ncol):\n",
    "                    data[icol] = np.append(data[icol],float(strings[icol]))\n",
    "            cnt += 1\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees TEKAL file met Latin Hyper Cube parameter sets\n",
    "LHCSets = readTEKAL('RUN002_LHSsampling.tek','XLHS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([LHCSet[4] for LHCSet in LHCSets]+[666])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least-squares line fit\n",
    "def linfit(x,y):\n",
    "    nn = ma.count(x)\n",
    "    c = [(ma.sum(x*y)-ma.sum(x)*ma.sum(y)/nn)/(ma.sum(x*x)-ma.sum(x)*ma.sum(x)/nn)]\n",
    "    c.append((ma.sum(y)-c[0]*ma.sum(x))/nn)\n",
    "    return(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmic fits on the location parameters of the Beta distribution A and B\n",
    "q0 = 3000\n",
    "clog_a1 = linfit(qref-q0,np.log(qref-a))\n",
    "clog_b1 = linfit(qref-q0,np.log(b-qref))\n",
    "\n",
    "# linear fits on the shape parameters alpha and beta\n",
    "c_alpha1 = linfit(qref,alpha)\n",
    "c_beta1 = linfit(qref,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A(q_r)\\,=\\,q_r\\,-\\,C_{A1}\\exp\\left(C_{A2}(q_r-q_0)\\right)\\\\ \\,\\\\ \n",
    "B(q_r)\\,=\\,q_r\\,+\\,C_{B1}\\exp\\left(C_{B2}(q_r-q_0)\\right)\\\\ \\,\\\\\n",
    "\\alpha(q_r)\\,=\\,\\max\\left(1,C_{\\alpha 1}\\,+\\,C_{\\alpha 2}q_r\\right)\\\\ \\,\\\\\n",
    "\\beta(q_r)\\,=\\,\\max\\left(1,C_{\\beta 1}\\,+\\,C_{\\beta 2}q_r\\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qref,a,'bo',label='A-parameter, lower extent')\n",
    "fig = plt.gcf()\n",
    "ax=plt.gca()\n",
    "ax.set_ylim([10000,21000])\n",
    "ax.plot(qref,b,'ro',label='B-parameter, upper extent')\n",
    "ax.plot(qref,qref,'g--',label='Reference discharge')\n",
    "ax.set_xlim([10000,21000])\n",
    "\n",
    "#logarithmic fits\n",
    "qs=np.array(list(range(3000,18000,100)))\n",
    "ax.plot(qs,qs-np.exp(clog_a1[0]*(qs-q0)+clog_a1[1]),'b.-',label=\"Q-%.3f * exp(%.3e*(Q - %.0f))\"%(np.exp(clog_a1[1]),clog_a1[0],q0))\n",
    "ax.plot(qs,qs+np.exp(clog_b1[0]*(qs-q0)+clog_b1[1]),'r.-',label=\"Q+%.3f * exp(%.3e*(Q - %.0f))\"%(np.exp(clog_b1[1]),clog_b1[0],q0))\n",
    "\n",
    "fig.set_size_inches(13,9)\n",
    "ax.set_xlabel('Reference discharge [m3 s-1]')\n",
    "ax.set_ylabel('A, B, Ref [m3 s-1]')\n",
    "ax.set_title('Extents A and B of the fit 4-parameter Beta distribution')\n",
    "lgnd = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combi meteo (normaal) en hydraulische onzekerheid (beta-verdeling) door samplen en opnieuw Beta fitten\n",
    "# q_Meteo gesampled uit de bovenstaande onzwekerheidsband voor de meteo\n",
    "# q_Hydraulica gesampled uit een beta-verdeling met verwachting 0\n",
    "# gesommeerd\n",
    "# Beta verdeling gefit\n",
    "\n",
    "def CombiNormalAndBeta(betaparameters,normalparameters,nx):\n",
    "    alpha = betaparameters[0]\n",
    "    beta = betaparameters[1]\n",
    "    AA = betaparameters[2]\n",
    "    BB = betaparameters[3]\n",
    "#   DD = sigma0*(alpha+beta)*((alpha+beta+1)/(alpha*beta))**0.5     # DD for s given sigma\n",
    "    DD = BB - AA                                                    # Keep the same interval\n",
    "    AA = -alpha*DD/(alpha+beta)                                     # Zero mean\n",
    "    BB = beta*DD/(alpha+beta)\n",
    "    \n",
    "    mu = normalparameters[0]\n",
    "    sigma = normalparameters[1]\n",
    "\n",
    "    betas=np.random.beta(alpha,beta,nx)*DD+AA\n",
    "    normals=np.random.normal(mu,sigma,nx)\n",
    "    sums=betas+normals\n",
    "    est2 = fb.fitBetaQuantiles(sums)\n",
    "    return est2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "sample_size = 10000\n",
    "mu=rijn_new['mu']\n",
    "sgv=rijn_new['sgv']\n",
    "sgm=rijn_new['sigma']\n",
    "\n",
    "def effective_beta_quantiles(stdgumvar, sample_size):\n",
    "    qhbv = interpolate(sgv,mu,stdgumvar)                   \n",
    "    sigma = interpolate(sgv,sgm,stdgumvar)\n",
    "    F, normals = quantilesetnormal(sample_size,qhbv,sigma)    \n",
    "    hydrologic_uncertainty=regression_2018(normals)\n",
    "    \n",
    "    qsbk = regression_2018([qhbv])[0]\n",
    "    alpha = max(1.0,c_alpha1[0]*qsbk+c_alpha1[1]) \n",
    "    beta = max(1.0,c_beta1[0]*qsbk+c_beta1[1])\n",
    "    AA = qsbk-np.exp(clog_a1[0]*(qsbk-q0)+clog_a1[1])\n",
    "    BB = qsbk+np.exp(clog_b1[0]*(qsbk-q0)+clog_b1[1])\n",
    "    DD = BB - AA                                                    # Keep the same interval\n",
    "    mean = alpha/(alpha+beta)*DD+AA\n",
    "    BB = BB - mean\n",
    "    AA = AA - mean\n",
    "    F, betas = quantilesetbeta(sample_size,alpha,beta,AA,BB)    \n",
    "    hydraulic_uncertainty=betas\n",
    "\n",
    "    sumlist = []\n",
    "    for h1 in hydrologic_uncertainty:\n",
    "        for h2 in hydraulic_uncertainty:\n",
    "            sumlist.append(h1+h2)\n",
    "    sums=np.array(sumlist)\n",
    "    est2 = fb.fitBetaQuantiles(sums)\n",
    "    beta_parameters = (alpha,beta,AA,BB)\n",
    "    normal_parameters = (qhbv,sigma)\n",
    "    return (est2, sums, beta_parameters, normal_parameters)\n",
    "\n",
    "def effective_beta_random(stdgumvar, sample_size):\n",
    "    qhbv = interpolate(sgv,mu,stdgumvar)\n",
    "    sigma = interpolate(sgv,sgm,stdgumvar)\n",
    "    normals = np.random.normal(qhbv,sigma,sample_size)     # trek een normaal verdeelde met mu=qref en sigma(qref)\n",
    "    hydrologic_uncertainty=regression_2018(normals)         # haal deze door de HBV->SOBEK regressie\n",
    "\n",
    "    qsbk = regression_2018([qhbv])[0]\n",
    "    alpha = max(1.0,c_alpha1[0]*qsbk+c_alpha1[1]) \n",
    "    beta = max(1.0,c_beta1[0]*qsbk+c_beta1[1])\n",
    "    AA = qsbk-np.exp(clog_a1[0]*(qsbk-q0)+clog_a1[1])\n",
    "    BB = qsbk+np.exp(clog_b1[0]*(qsbk-q0)+clog_b1[1])\n",
    "    DD = BB - AA                                                    # Keep the same interval\n",
    "    mean = alpha/(alpha+beta)*DD+AA\n",
    "    BB = BB - mean\n",
    "    AA = AA - mean\n",
    "    hydraulic_uncertainty=np.random.beta(alpha,beta,sample_size)*DD+AA # trek een Beta verdeelde \n",
    "    sums=hydrologic_uncertainty\n",
    "    # sums=hydraulic_uncertainty+hydrologic_uncertainty\n",
    "    est2 = fb.fitBetaQuantiles(sums)\n",
    "    beta_parameters = (alpha,beta,AA,BB)\n",
    "    normal_parameters = (qhbv,sigma)\n",
    "    return (est2, sums, beta_parameters, normal_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  recalc_beta = True: Bereken Beta parameters langs de gumbel-as  door willekeurige trekkingen te fitten\n",
    "#  recalc_beta = False: Haal voorberekende resultaten van een file (berekening duurt erg lang)\n",
    "recalc_beta = True\n",
    "size = 50000\n",
    "estimates = []\n",
    "if recalc_beta:\n",
    "    with open('effective_beta_new.txt','w') as effbeta:\n",
    "        for sgvval in np.array(list(range(-4,23)))*0.5:\n",
    "            result=effective_beta_random(sgvval, size)        \n",
    "            est2=result[0]\n",
    "            betaparams=result[2]\n",
    "            estimates.append((sgvval,est2))\n",
    "            effbeta.write(\"%15.5e, %15.5e, %15.5e, %15.5e, %15.5e\\n\"%(sgvval, est2[0], est2[1], est2[2], est2[3]))\n",
    "            print(betaparams)\n",
    "else:\n",
    "    if os.path.isfile('effective_beta.txt'):\n",
    "        with open('effective_beta.txt','r') as effbeta:\n",
    "            while True:\n",
    "                l = effbeta.readline()\n",
    "                if not l:\n",
    "                    break\n",
    "                floats = [float(lsub) for lsub in l.split(',')]\n",
    "                est2 = np.array(floats[1:5])\n",
    "                sgvval = floats[0]\n",
    "                estimates.append((sgvval,est2))\n",
    "                sys.stdout.write(\"%15.5e, %15.5e, %15.5e, %15.5e, %15.5e\\n\"%(sgvval, est2[0], est2[1], est2[2], est2[3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leid verwachting, variantie, scheefheid, kurtosis en het tweezijdig 95% betrouwbaarheidsinterval af uit de beta paerameters\n",
    "yy = []\n",
    "pct_025 = []\n",
    "pct_975 = []\n",
    "pct_500 = []\n",
    "meanlist = []\n",
    "varlist = []\n",
    "skewlist = []\n",
    "kurtlist = []\n",
    "\n",
    "for est in estimates:\n",
    "    yy.append(est[0])\n",
    "    alpha_fit=est[1][0]\n",
    "    beta_fit=est[1][1]\n",
    "    AA_fit=est[1][2]\n",
    "    BB_fit=est[1][3]\n",
    "    pct_025.append(fb.beta_reverse(alpha_fit,beta_fit,AA_fit,BB_fit,0.025))\n",
    "    pct_500.append(fb.beta_reverse(alpha_fit,beta_fit,AA_fit,BB_fit,0.500))\n",
    "    pct_975.append(fb.beta_reverse(alpha_fit,beta_fit,AA_fit,BB_fit,0.975))\n",
    "    mean, var, skew, kurt = fb.BetaMoments(alpha_fit,beta_fit,AA_fit,BB_fit)\n",
    "    meanlist.append(mean)\n",
    "    varlist.append(var)\n",
    "    skewlist.append(skew)\n",
    "    kurtlist.append(kurt)\n",
    "np_yy = np.array(yy)\n",
    "np_pct025 = np.array(pct_025)\n",
    "np_pct500 = np.array(pct_500)\n",
    "np_pct975 = np.array(pct_975)\n",
    "np_mean = np.array(meanlist)\n",
    "np_var = np.array(varlist)\n",
    "np_skew = np.array(skewlist)\n",
    "np_kurt = np.array(kurtlist)\n",
    "\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voer een uitintegratie uit voor de nieuwe resultaten\n",
    "def cdfbeta(y,parms):\n",
    "    return fb.beta_forward(parms[0],parms[1],parms[2],parms[3],y)\n",
    "\n",
    "rijn_new['uitintegratie'] = {}\n",
    "np_yy = np.array([est[0] for est in estimates])\n",
    "rijn_parms_new = {'distpar' : [est[1] for est in estimates],\n",
    "                  'F' : np.exp(-np.exp(-np_yy))}\n",
    "rijn_new['uitintegratie']['levels'] = np.array(list(range(6000,21000,100)))\n",
    "rijn_cdf_new = outintegrate(rijn_parms_new, rijn_new['uitintegratie']['levels'] , cdfbeta)\n",
    "rijn_new['uitintegratie']['sgv'] = -np.log(-np.log(rijn_cdf_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot nieuw versus observations met \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 2000\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "ax.plot(np_yy,np_mean,'b-',label=\"GRADE'21\")\n",
    "ax.plot(np_yy,np_pct025,'b--')\n",
    "ax.plot(np_yy,np_pct975,'b--')\n",
    "#ax.plot(rijn_new['uitintegratie']['sgv'],rijn_new['uitintegratie']['levels'],'k-',label=\"GRADE'21 - uitgeintegreerd\")\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "ax.plot([-1,13],[17750,17750],'k--',alpha=0.3, label=\"Maximum discharge (current situation)\")\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_03a.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot oud versus observations\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 2000\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "#ax.plot(rijn_old['sgv'],rijn_old['mu'],'r-',label=\"WBI2017\")\n",
    "#ax.plot(rijn_new['sgv'],regression_2018(rijn_new['mu']),'m-',label=\"GRADE'21\")\n",
    "ax.plot(np_yy,np_mean,'b-',label=\"GRADE'21\")\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_03c.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot oud en nieuw uitgeïntegreerd versus observations\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 2000\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "ax.plot(rijn_old['uitintegratie']['sgv'],rijn_old['uitintegratie']['levels'],'r-',label=\"WBI2017 - processed uncertainties\")\n",
    "ax.plot(rijn_new['uitintegratie']['sgv'],rijn_new['uitintegratie']['levels'],'b-',label=\"GRADE'21 - processed uncertainties\")\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_04.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit een functioneel voorschrift uit de berekende punten op de manier van Henk vd Boogaerd\n",
    "\n",
    "# plot a piece-wise linear\n",
    "x = [0,   4.7,  8,    12,   20     ]\n",
    "y = [5250,13500,14800,17400,17400  ]\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 2000\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "ax.plot(rijn_new['uitintegratie']['sgv'],rijn_new['uitintegratie']['levels'],'b*',label=\"GRADE'21 - processed uncertainties\")\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "ax.plot(x,y,'r-+',label='Linear fit')\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_05.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Gedeeltelijk lineaire benadering met exponentiële overgangen</H2>\n",
    "Dit is een generalisatie van de uitdrukking die Henk vd Boogaard gebruikt voor <tt>regressie_2018</tt>, namelijk:\n",
    "$$\n",
    "y(x)\\,=\\,\n",
    "C\\,+r_1 x\n",
    "+ \\sum\\limits_{i=2}^n \\left(r_i-r_{i-1}\\right)\\,\\log\\left(1\\,+\\,\\exp\\left(\\frac{x-\\mu_{i-1}}{\\sigma_{i-1}}\\right)\\right)\\,\\,,\n",
    "$$\n",
    "geïmplementeerd in de onderstaande functie <tt>pwlin</tt>.\n",
    "De knikpunten (op de horizontale as) bevinden zichop de $\\mu_i$, de helling van de stukken is voorgeschreven door de $r_i$ op het interval $\\left(\\mu_{i-1},\\mu_i\\right)$, $C$ is een offset en de $\\sigma_i$ bepaalt de scherpte van het knikpunt bij $\\mu_i$, m.a.w. hoe glad de overgang verloopt. Zo kan in termen van een beperkte set parameters bovenstaande curve redelijk beschreven worden. Er zijn grofweg vier intervallen te onderscheiden, dus vier hellingen en drie knikpunten.\n",
    "\n",
    "Gegeven een set knikpunten $\\left(x_i,y_i\\right)$, kan bepaald worden:\n",
    "<ul>\n",
    "    <li>$r_i=\\left(y_i-y_{i-1}\\right)/\\left(x_i-x_{i-1}\\right)$</li>\n",
    "    <li>$\\mu_i=r_i$</li>\n",
    "    <li>$C=y_1-r_1x_1$</li>\n",
    "</ul>\n",
    "De $\\sigma_i$ moeten nog naar smaak gekozen worden en hangen samen met hoe dicht het knikpunt benaderd moet worden.\n",
    "Omdat de knikpunten zelf geen onderdeel van de data zijn en ook omdat de curve een beetje glad moet blijven, hoeven de $\\sigma_i$ in dit geval niet heel klein te zijn.\n",
    "Dit is geïmplementeerd in de onderstaande functie <tt>pwlin_points</tt>. Dan zijn er dus 5 punten nodig in dit geval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Piecewise linear with exonential smooth transitions\n",
    "#Dit is de aanpak van Henk vd Boogaard, maar dan generieker:\n",
    "\n",
    "MAX_EXP = 700.     # max argument of the exponent function\n",
    "def pwlin(x,r,mu,sigma):\n",
    "    x_ = []\n",
    "    for value in x:\n",
    "        y = r[0] + r[1]*value\n",
    "        for i in range(1,len(mu)):\n",
    "            z = (value-mu[i])/sigma[i]\n",
    "            if (z<=MAX_EXP):\n",
    "                a = np.log(1+np.exp(z))\n",
    "            else:\n",
    "                a = z\n",
    "            y += (r[i+1]-r[i])*sigma[i]*a\n",
    "        x_.append(y)\n",
    "    return x_\n",
    "\n",
    "def pwlin_points(x,xs,ys,sigma):\n",
    "    r=np.array([ys[0] - ((ys[1]-ys[0])/(xs[1]-xs[0]))*xs[0]])\n",
    "    for i in range(1,len(xs)):\n",
    "        r = np.append(r, (ys[i]-ys[i-1])/(xs[i]-xs[i-1]))\n",
    "    print (r)\n",
    "    return pwlin(x,r,xs[:-1],sigma)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benadering(sgv):\n",
    "    xss = np.array([0,   4.7,  8,    12.0,   20 ])\n",
    "    yss = np.array([5250,13500,14800, 17300, 17400])\n",
    "    sgm = np.array([np.nan,0.3,0.1,0.5,0.1])\n",
    "    return pwlin_points(sgv,xss,yss,sgm)\n",
    "\n",
    "# plot benadering\n",
    "sgv = np.linspace(0, 13, num=200)\n",
    "qq = benadering(sgv)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 2000\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "ax.plot(rijn_new['uitintegratie']['sgv'],rijn_new['uitintegratie']['levels'],'k-',label=\"GRADE'21 - processed uncertainties\")\n",
    "ax.plot(sgv,qq,'r-',label='Discharge statistics (as function)')\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_06.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile =r\"read_Qmax_sums_results.csv\"\n",
    "\n",
    "df = pd.read_csv(infile, sep=';', index_col=0)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "ref = df.loc[['Sum113']]\n",
    "\n",
    "scenarios = ['Sum101','Sum102','Sum103',\n",
    "             'Sum104','Sum105','Sum106',\n",
    "             'Sum107','Sum108','Sum109',\n",
    "             'Sum110','Sum111','Sum112',]\n",
    "\n",
    "x_start = pd.Series(np.arange(250,12500,250))\n",
    "y_start = pd.Series(np.arange(250,12500,250))\n",
    "\n",
    "func = []\n",
    "for scenario in scenarios:\n",
    "    fig1, ax1 = plt.subplots(figsize=(12,6))\n",
    "    scenA = df.loc[[scenario]]\n",
    "    \n",
    "    df2 = pd.concat([ref, scenA], axis=0).T\n",
    "    x = df2['Sum113'].sort_values()\n",
    "    y = df2[scenario].sort_values()\n",
    "    \n",
    "    x = pd.concat([x_start, x], axis=0)\n",
    "    x.reindex()\n",
    "    y = pd.concat([y_start, y], axis=0)\n",
    "    \n",
    "    z = np.polyfit(x, y, 3)\n",
    "    f = np.poly1d(z)\n",
    "    func.append(f)\n",
    "    \n",
    "    # calculate new x's and y's\n",
    "    x_new = np.linspace(x.iloc[0], x.iloc[-1], 50)\n",
    "    y_new = f(x_new)\n",
    "    \n",
    "    ax1.plot(x,y, 'ro', label=scenario)\n",
    "    ax1.plot(x_new,y_new, 'r', label=scenario + \"_fit\")\n",
    "\n",
    "    ax1.plot([0,20000],[0,20000], 'k--')  \n",
    "    ax1.set_xlim(10000,20000)\n",
    "    ax1.set_ylim(10000,)\n",
    "    plt.legend()\n",
    "    # plt.savefig(f\"{scenario}_linfit.png\", dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(12,6))\n",
    "\n",
    "colors = ['blue','orange','red']\n",
    "for scenario, color in zip(scenarios[0:3], colors):\n",
    "    \n",
    "    scenA = df.loc[[scenario]]\n",
    "    \n",
    "    df2 = pd.concat([ref, scenA], axis=0).T\n",
    "    x = df2['Sum113'].sort_values()\n",
    "    y = df2[scenario].sort_values()\n",
    "    \n",
    "    x = pd.concat([x_start, x], axis=0)\n",
    "    x.reindex()\n",
    "    y = pd.concat([y_start, y], axis=0)\n",
    "    \n",
    "    z = np.polyfit(x, y, 5)\n",
    "    f = np.poly1d(z)\n",
    "    func.append(f)\n",
    "    \n",
    "    # calculate new x's and y's\n",
    "    x_new = np.linspace(x.iloc[0], x.iloc[-1], 50)\n",
    "    y_new = f(x_new)\n",
    "    \n",
    "    ax1.scatter(x,y, marker = 'o', color=color, label=scenario)\n",
    "    ax1.plot(x_new,y_new, color=color, label=scenario + \"_fit\")\n",
    "\n",
    "ax1.plot([0,20000],[0,20000], 'k--')  \n",
    "ax1.set_xlim(10000,20000)\n",
    "# ax1.set_ylim(13500,20000)\n",
    "# ax1.set_xlim(0,20000)\n",
    "ax1.set_ylim(10000,)\n",
    "plt.legend()\n",
    "#plt.savefig(f\"{scenario}_allinone.png\", dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot oud versus observations\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0.325,12)\n",
    "ymax = 20000 \n",
    "yrange = 500\n",
    "ax.set_ylim(0,ymax)\n",
    "\n",
    "ax.set_xlim(8,12)\n",
    "ax.set_ylim(14000,17000)\n",
    "\n",
    "scenarios = ['Sum101','Sum102','Sum103']\n",
    "\n",
    "for scenario in scenarios:\n",
    "#scenario = 'Sum102'\n",
    "\n",
    "    scenA = df.loc[[scenario]]\n",
    "\n",
    "    df2['Sum113']\n",
    "\n",
    "    df2 = pd.concat([ref, scenA], axis=0).T\n",
    "    x = df2['Sum113'].sort_values()\n",
    "    y = df2[scenario].sort_values()\n",
    "\n",
    "    x = pd.concat([x_start, x], axis=0)\n",
    "    x.reindex()\n",
    "    y = pd.concat([y_start, y], axis=0)\n",
    "\n",
    "    z = np.polyfit(x, y, 5)\n",
    "    f = np.poly1d(z)\n",
    "    func.append(f)\n",
    "\n",
    "    np_mean_new = f(np_mean)\n",
    "\n",
    "    ax.plot(np_yy[np_mean_new>13000],np_mean_new[np_mean_new>13000],linestyle='--',label=\"GRADE'21 - %s\" %(scenario))\n",
    "\n",
    "ax.plot(np_yy,np_mean,'b-',label=\"GRADE'21\")\n",
    "ax.plot(rijn_obs['sgv'],rijn_obs['mu'],'g*',label=\"Observations\")\n",
    "\n",
    "ax=plt.gca()\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "ax.legend(loc=\"upper left\")\n",
    "add_gum_axis(Tretlist,ax,ymax,yrange)\n",
    "plt.savefig('plots//plot_10_all_zoom.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De totale uitdrukking wordt nu:\n",
    "$$Q(y)\\,=\\,C\\,+\\,r_1 y\\,+\\,(r_2-r_1)\\,\\sigma_1\\log\\left(1+\\exp\\left(\\frac{y-\\mu_1}{\\sigma_1}\\right)\\right)+\\,(r_3-r_2)\\,\\sigma_2\\log\\left(1+\\exp\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)\\right)$$\n",
    "$$\\phantom{Q(y)\\,=\\,C\\,+\\,r_1 y\\,}+\\,(r_4-r_3)\\,\\sigma_3\\log\\left(1+\\exp\\left(\\frac{y-\\mu_3}{\\sigma_3}\\right)\\right)+\\,(r_5-r_4)\\,\\sigma_4\\log\\left(1+\\exp\\left(\\frac{y-\\mu_4}{\\sigma_4}\\right)\\right)$$\n",
    "\n",
    "<table>\n",
    "<tr>    \n",
    "    <td>\n",
    "$C = 5250.0$ <br>\n",
    "$r_1 = 1755.3$ <br>\n",
    "$r_2 = 393.9$  <br>\n",
    "$r_3 = 625.0$<br>\n",
    "$r_4 = 12.5$<br>\n",
    "$r_5 = 0.0$<br>\n",
    "    </td>\n",
    "<td>\n",
    "$\\mu_1 = 0.0$ <br>\n",
    "$\\mu_1 = 4.7$ <br>\n",
    "$\\mu_2 = 8.0$  <br>\n",
    "$\\mu_3 = 12.0$<br>\n",
    "    </td>\n",
    "</tr>\n",
    "Met $y$ de standardised gumbel variate, uitgedrukt in de herhalingstijd $T_r$ als:\n",
    "$$\n",
    "y\\,=\\,-\\log\\left(-\\log\\left(1-\\frac 1 {T_r}\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math   # Crucial import !!!\n",
    "def werklijn_functie(x, fit_regr=False):\n",
    "    c      = 342.254390\n",
    "    r1     = 0.91577902\n",
    "    mu1    = 14442.2780 #ORIG\n",
    "    sigma1 = 307.118620\n",
    "    r2     = 0.32752076\n",
    "    mu2    = 18573.2200 #ORIG\n",
    "    sigma2 = 2.71804449E-14\n",
    "    r3     = 0.53632634 #ORIG\n",
    "    mu3    = 21904.1250 #ORIG\n",
    "    sigma3 = 136.807970  \n",
    "    r4     = 0.21296795\n",
    "    mu4    = 26177.6500 #ORIG\n",
    "    sigma4 = 79.5476640\n",
    "    r5     = 0.00000000\n",
    "    if fit_regr == True:\n",
    "        mu1    = 14800.0000\n",
    "        mu2    = 17750.0000\n",
    "        r3     = 0.75000000\n",
    "        mu3    = 20000.0000\n",
    "    \n",
    "    x_ = []\n",
    "    for value in x:\n",
    "        z1 = (value-mu1)/sigma1\n",
    "        z2 = (value-mu2)/sigma2\n",
    "        z3 = (value-mu3)/sigma3\n",
    "        z4 = (value-mu4)/sigma4\n",
    "        \n",
    "        a1 = (r1*value)\n",
    "        a2 = ((r2-r1)*sigma1*np.log(1+np.exp(z1)))\n",
    "        try:\n",
    "            a3 = ((r3-r2)*sigma2*np.log(1+math.exp(z2)))\n",
    "        except:\n",
    "            a3 = ((r3-r2)*sigma2*z2)\n",
    "        a4 = ((r4-r3)*sigma3*np.log(1+np.exp(z3)))\n",
    "        a5 = ((r5-r4)*sigma4*np.log(1+np.exp(z4)))\n",
    "        \n",
    "        y = c + a1 + a2 + a3 + a4 + a5\n",
    "        x_.append(y)\n",
    "\n",
    "    return x_\n",
    "\n",
    "\n",
    "# Genereer een tabel voor gezette herhalingstijden\n",
    "table = {'Herhaaltijd':Tretlist}\n",
    "qmax_old = []\n",
    "sigma_old = []\n",
    "uit_old = []\n",
    "qmax_new = []\n",
    "sigma_new = []\n",
    "uit_new = [] \n",
    "table={'Herhaaltijd':Tretlist}\n",
    "for tr in Tretlist:\n",
    "    qmax_old.append(interpolate(rijn_old['sgv'],rijn_old['mu'],-np.log(-np.log(1.-1./tr)),default=np.nan))\n",
    "    sigma_old.append(interpolate(rijn_old['sgv'],rijn_old['sigma'],-np.log(-np.log(1.-1./tr)),default=np.nan))\n",
    "    uit_old.append(interpolate(rijn_old['uitintegratie']['sgv'],rijn_old['uitintegratie']['levels'],-np.log(-np.log(1.-1./tr)),default=np.nan))\n",
    "    qmax_new.append(interpolate(rijn_new['sgv'],rijn_new['mu'],-np.log(-np.log(1.-1./tr)),default=np.nan))\n",
    "    sigma_new.append(interpolate(rijn_new['sgv'],rijn_new['sigma'],-np.log(-np.log(1.-1./tr)),default=np.nan))\n",
    "    uit_new.append(interpolate(rijn_new['uitintegratie']['sgv'],rijn_new['uitintegratie']['levels'],-np.log(-np.log(1.-1./tr)),default=np.nan))\n",
    "table['Qmax oud']=qmax_old\n",
    "table['Sigma oud']=sigma_old\n",
    "table['Uitgeïntegreerd oud']=np.round(np.array(uit_old)*100)/100.\n",
    "table['Qmax nieuw']=np.round(np.array(qmax_new)*100)/100.\n",
    "table['Sigma nieuw']=sigma_new\n",
    "table['Uitgeïntegreerd nieuw']=np.round(np.array(uit_new)*100)/100.\n",
    "pd.DataFrame(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Relatieve bijdrage van de ruwheid aan de totale onzekerheid</H2>\n",
    "De totale variantie is als volgt opgebouwd:\n",
    "$$\n",
    "\\sigma^2_{totaal}\n",
    "\\,=\\,\n",
    "\\sigma^2_{jac\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regressie (Least-Squares sense)\n",
    "def linearfit(y,x):\n",
    "    # fits the linear expression y[j] = sum(alpha[i]*x[ij]) + B\n",
    "    # y is a numpy array size [nsample]\n",
    "    # x is a numpy array size [nsample, nvar]\n",
    "    ns = np.shape(y)[0]\n",
    "    nv = np.shape(x)[1]\n",
    "    A = np.zeros([nv+1,nv+1])\n",
    "    B = np.zeros([nv+1])\n",
    "    for j in range(ns):\n",
    "        for i in range(nv):\n",
    "            for k in range(i,nv):\n",
    "                A[i,k] += x[j,i]*x[j,k]\n",
    "            A[i,nv] += x[j,i]\n",
    "            B[i] += y[j]*x[j,i]\n",
    "        A[nv,nv] += 1.\n",
    "        B[nv] += y[j]\n",
    "    for k in range(1,nv+1):\n",
    "        for i in range(k):\n",
    "            A[k,i] = A[i,k]\n",
    "    alphas = np.linalg.solve(A, B)\n",
    "    return (alphas[:nv],alphas[nv])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
